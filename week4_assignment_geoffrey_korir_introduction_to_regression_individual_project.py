# -*- coding: utf-8 -*-
"""week4 assignment-Geoffrey Korir- Introduction to Regression Individual Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10VQkLwQxMzWjOMMiK61VFyBNlFLd4YnV

#Introduction to Regression Project

##Problem Statement

Legacy plans has been used widely by Megaline subscribers. Megaline wants to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since you’ve already performed the data preprocessing step, you can move straight to creating the model. Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset.

## Data Importation
"""

import pandas as pd

# Dataset URL (CSV File): https://bit.ly/UsersBehaviourTelco

megaline_df = pd.read_csv("https://bit.ly/UsersBehaviourTelco")

megaline_df.head()

"""##Data Exploration"""

#get the shape of the df
megaline_df.shape

# Describe the Data
megaline_df.info()

# descripe data
megaline_df.describe()

#see the amount of data on each target
megaline_df['is_ultra'].value_counts()

# Expressing those promoted and those not as a percentage
print('1. Smart plans users %,  ' 
      + str(round(((megaline_df["is_ultra"].isin([0]).sum())/megaline_df.shape[0])*100,2)) + ' %')
print('2. Smart plans users on Ultra plan % , ' 
      + str(round(((megaline_df["is_ultra"].isin([1]).sum())/megaline_df.shape[0])*100,2)) + ' %')

"""##Data Cleaning

Data cleaning has already been done for this data set as per the instructions

*Since you’ve already performed the data preprocessing step, you can move straight to creating the model*

##Data Preparation
"""

# check correlation of features and target

import matplotlib.pyplot as plt
import seaborn as sns

features = megaline_df.columns
corr_= megaline_df[features].corr()
plt.figure(figsize=(6,4))
sns.heatmap(corr_, annot=True, fmt = ".2f", cmap = "BuPu");

# plot Histogram for features to show relationship between them and target 
for feature in features[:-1]:
  plt.hist(megaline_df[megaline_df['is_ultra']==1][feature], color= 'green', alpha = 0.7, label = 'Ultra', density=True)
  plt.hist(megaline_df[megaline_df['is_ultra']==0][feature], color= 'orange', alpha = 0.7, label = 'Smart', density=True)
  plt.title(feature)
  plt.ylabel('Probability')
  plt.xlabel(feature)
  plt.legend()
  plt.show()

# Split the source data into a training set, a validation set, and a test set.
from sklearn.model_selection import train_test_split

features = megaline_df.drop(['is_ultra'], axis=1)
target = megaline_df['is_ultra']

# set aside 20% of train and test data for evaluation
X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.2, random_state = 54321)

# Use the same function above for the validation set
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state= 54321) # 0.25 x 0.8 = 0.2

# Check the shape of our new datasets

print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"Y_train shape: {Y_train.shape}")
print(f"Y_test shape: {Y_test.shape}")
print(f"X_val shape: {Y_train.shape}")
print(f"Y_val shape: {Y_test.shape}")

"""##Data Modeling"""

# 3. Investigate the quality of different models by changing hyperparameters. Briefly
# describe the findings of the study.

from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
# RandomForestRegressor and is located in sklearn.ensemble module.
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

dec_regressor = DecisionTreeClassifier(random_state=27)
log_regressor = LogisticRegression()
fst_regressor = RandomForestClassifier(random_state= 14)


dec_regressor.fit(X_train, Y_train)
log_regressor.fit(X_train, Y_train)
fst_regressor.fit(X_train, Y_train)

# Making Predictions using the validation set
dec_y_pred = dec_regressor.predict(X_val)
log_y_pred = log_regressor.predict(X_val)
fst_y_pred = fst_regressor.predict(X_val)

from sklearn.metrics import mean_squared_error
# Finally, evaluating our models 
print(f'Decision Tree RMSE: {mean_squared_error(Y_val, dec_y_pred, squared=False)}')
print(f'Linear Regression RMSE:{mean_squared_error(Y_val, log_y_pred, squared=False)}')
print(f'Random Forest Classifier RMSE: {mean_squared_error(Y_val, fst_y_pred, squared=False)}')

from sklearn.metrics import classification_report
# print classification report for Decision Tree Regressor
print(f'DecisionTreeClassifier classification report:\n {classification_report(Y_test, dec_y_pred)}')

# print classification report for Logistic Regression
print(f'Logistic Regression classification report:\n {classification_report(Y_test, log_y_pred)}')

# print classification report for Random Forest Classifier 
print(f'Random Forest Classifier classification report:\n {classification_report(Y_test, fst_y_pred)}')

"""Our model perfomance accuracy were as follows:

DecisionTreeClassifier 0.57

Logistic Regression 0.65

Random Forest Classifier 0.59

###Model Improvement with Hyperparameters
"""

##find the best tree depth with best accuracy
from sklearn.metrics import accuracy_score
best_score = 0
for depth in range(1,10):
  model = DecisionTreeClassifier(max_depth=depth, random_state=27)
  model.fit(X_test, Y_test)
  pred = model.predict(X_val)
  score = accuracy_score(Y_val, pred)
  if score > best_score: best_score = score
print(f'Tree accuracy with Validation: {best_score} at depth of: {depth}')

#find the best n estimator for random forest with best accuracy
best_score = 0
for n in range(1,20):
  model = RandomForestClassifier(n_estimators=n, random_state=12345)
  model.fit(X_train, Y_train)
  score = model.score(X_val, Y_val)
  if score > best_score: best_score = score
print(f'Forest accuracy with Validation: {best_score} for n trees: {n}')

# Retrain our models with hyper parameteres 
dec_regressor = DecisionTreeClassifier(random_state=27,max_depth = 9 )
log_regressor = LogisticRegression()
fst_regressor = RandomForestClassifier(random_state= 14, n_estimators = 19)

dec_regressor.fit(X_train, Y_train)
log_regressor.fit(X_train, Y_train)
fst_regressor.fit(X_train, Y_train)

"""##Model Evaluation"""

# 4. Check the quality of the model using the test set.

# Making Predictions using the test set
dec_y_pred = dec_regressor.predict(X_test)
log_y_pred = log_regressor.predict(X_test)
fst_y_pred = fst_regressor.predict(X_test)


# evaluating our models 
print(f'Decision Tree RMSE: {mean_squared_error(Y_test, dec_y_pred, squared=False)}')
print(f'Linear Regression RMSE:{mean_squared_error(Y_test, log_y_pred, squared=False)}')
print(f'Random Forest Classifier RMSE: {mean_squared_error(Y_test, fst_y_pred, squared=False)}')

# 5. Additional task: sanity check the model. This data is more complex than what
# you’re used to working with, so it's not an easy task. We'll take a closer look at it
# later.

from sklearn.metrics import classification_report
# print classification report for Decision Tree Classifier 
print(f'DecisionTreeClassifier classification report:\n {classification_report(Y_test, dec_y_pred)}')

# print classification report for Logistic Regression
print(f'Logistic Regression classification report:\n {classification_report(Y_test, log_y_pred)}')

# print classification report for Random Forest Regressor
print(f'Random Forest Classifier classification report:\n {classification_report(Y_test, fst_y_pred)}')

"""##Findings and Recommendations

The acuracy score of our model is as follows after hyperparameter tunning

DecisionTreeClassifier 0.76 

Logistic Regression 0.67

Random Forest Classifier 0.77

This score tells us that it is possible to predict the plan of customers as to wether they are on smart or ultra with a fine accuracy.
Random Forest and Decision Tree perfromed better and therefore we recommend them to be used by the customer.
"""